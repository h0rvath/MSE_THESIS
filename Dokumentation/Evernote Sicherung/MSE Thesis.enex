<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE en-export SYSTEM "http://xml.evernote.com/pub/evernote-export2.dtd">
<en-export export-date="20170918T053506Z" application="Evernote/Windows" version="6.x">
<note><title>Basics &apos;cloud-tracking&apos;</title><content><![CDATA[<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE en-note SYSTEM "http://xml.evernote.com/pub/enml2.dtd">

<en-note><div><span><br/></span></div><div><span><b><u>Basics: Bestimmung der Sonneneinstrahlung mittels &apos;cloud-tracking&apos;</u></b></span></div><div><br/></div><div><br/></div><div><span>spatial-&gt; räumlichen</span></div><div><span>Annahmen: Wolken bewegen sich relat. langsam mit konst. Geschwindigkeit und verändern ihre Form wärend kurzen</span></div><div><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Zeitspannen kaum.</span></div><div><span>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></div><div><span>Die maximale Vorhersagezeit ist bestimmt durch die Geschwindigkeit und Höhe der Wolke. Sie wird vorgegeben durch</span></div><div><span>die Zeit welche eine Wolkenformation zum Durchlaufen des aufgenommenen Bildes benötigt (tipischerweise 15-30 Minuten)</span></div><div><span>Es werden häufig CCD-Kameras (charge-coupled device chips) mit Weitwinkel-Objektiven verwendet. Die Bilder werden</span></div><div><span>auf das sogennate RBR - Verhältnis (red-to-blue ratio) hin ausgewertet. RBR ist dabei ein Indikator für das Vorhandensein</span></div><div><span>oder Fehlen einer Wolke (unterschiedliche Lichtbrechung abhängig von der Luftfeuchtigkeit).</span></div><div><span>Ein hoher RBR = Wolken und ein tiefer RBR = klarer Himmel. Zudem kann die Helligkeit einzelner Pixel zusätzlich</span></div><div><span>zur Bestimmung der Bewölkung verwendet werden.</span></div><div><span>Sogenannte &apos;binary cloud decision maps&apos; -&gt; weiss = Wolke, schwarz = wolkenfreier Himmel können aus den RBR erstellt werden.</span></div><div><span>Hierzu wird aufgrund eines Thresholds binär entschieden. Zusätzlich kann auch zwischen hellen und dunklen Wolken</span></div><div><span>unterschieden werden.</span></div><div><span>Die Wolken-Karte (Schattenwurf) muss auf den Erdboden transformiert (projeziert werden). Dazu wird die Höhe der</span></div><div><span>Wolkendecke sowie die Position der Sonne benötigt. (Deshalb ist auch eine hohe räumliche Auflösung notwendig!)</span></div><div><span>Bestimmung der Wolkenbewegung z.B. nach Chow et al. (2011) indem die normalisierter Kreuzkorrelation bestimmter Regionen</span></div><div><span>(dort wo Wolken vorhanden sind) zwischen konsekutiven Bildern maximiert wird .</span></div><div><span>Alternativ hierzu kann das Verfahren &apos;optical Flow&apos; aus der Bildverarbeitung (computer vision) angewendet werden.</span></div><div><span>Mittels denn CMV&apos;s (cloud motion vectors) kann die zukünftige Position einer Wolke bestimmt werden.</span></div><div><span>Wolken-Schattenkarten erhält man mittels der Projektion der zukünftige Position einer Wolke. Aus den Wolken-Schattenkarten</span></div><div><span>lassen sich die erwarteten Sonnenstrahlungsdichten abschätzen.</span></div><div><span>Langzeit Vorhersagen:</span></div><div><span>---------------------</span></div><div><span>In erster Linie bestimmt die Aufnahmedauer die grösstmögliche Vorhersagezeit. Diese wiederum ist abhängig von Wolkengeschwindigkeit</span></div><div><span>sowie der zurückgelegten Distanz, also im Falle eine all Sky-Kamera der tatsächlichen Horizont zu Horizont Distanz die im</span></div><div><span>besten Fall nur von der Beobachtungshöhe anhängt.</span></div><div><span>Bei freier Sicht und einer Beobachtungshöhe von 10m beträgt die Horizont zu Horizont Distanz ca 150Km. Bewegt sich eine Wolke</span></div><div><span>mit einer durchschnittlichen Geschwindigkeit von ca. 14.5km/h, dann beträgt die Dauer um von einem zum anderen Horizont zu</span></div><div><span>gelangen ca. = 0.78*60 = 45 Minuten was bereits unter einer Stunde liegt.</span></div><div><span>Um dennoch Vorhersagen über grössere Zeiträume treffen zu können sind zusätzliche Daten notwendig wie sie z.B. über</span></div><div><span>Satteliten-Bilder gewonnen werden können. (Irradiance Forecasting with NWP&apos;s) Eine Übersicht gibt (Kalnay 2003).</span></div><div><br/></div><div><span>Zusammenfassend:</span></div><div><span>----------------------</span></div><div><span>1) Bilder der lokalen Wolkendecke von Kamera/Satteliten</span></div><div><span>2) Vroausgesetzt Wolkenform ändert kaum: CMV&apos;s (cloud motion vectors) bestimmen, indem die Position bestimmter</span></div><div><span>&nbsp;&nbsp;&nbsp;Punkte in aufeinanderfolgende Bilder miteinander verglichen werden.</span></div><div><span>3) Unter der Annahme dass sich die Geschwindigkeit der Wolke nicht sehr ändert, wird die zukünftige Position der</span></div><div><span>&nbsp;&nbsp;&nbsp;Wolke (aus den CMV&apos;s) berechnet (extrapoliert).</span></div><div><span>&nbsp;&nbsp;&nbsp;</span></div><div><span>Teilaspekte/Schwierigkeiten:</span></div><div><span>--------------------------------</span></div><div><span>Wolkenhöhe:</span></div><div><span>Die tatsächliche Wolkenhöhe ist entscheidend für eine gute Prognose. Sehr genaue Werte erhält man mittels einem</span></div><div><span>Ceilometer (LIDAR).</span></div><div><span>Different methods to determine cloud height using information from more than one sky imager are shortly introduced</span></div><div><span>in Urquhart et al. (2013) and Prahl et al. (2014).&nbsp;&nbsp;&nbsp;</span></div><div><span>clear-sky library (Chow et al. 2011):</span></div><div><span>Ungleichmässiges &apos;clear-sky&apos;-Signal in Abhängigkeit von der Position der Sonne</span></div><div><span>Wird verwendet um noch differenzierter die Helligkeit zu klassifizieren. Man unterscheidet so auch</span></div><div><span>zwischen hellen und dunklen Wolken oder auch hellem und dunklem Himmel.</span></div><div><span>cloud classification algorithm (2010 Heinle, Macke and Srivastav):</span></div><div><span>berechnet die optische Dichte von Wolken und ermöglicht zusätzlich die Wolkenhöhe</span></div><div><span>abzuschätzen.</span></div><div><span>(Unsicherheit bei der) Bestimmung der Sonnenstrahlungsdichte:</span></div><div><span>Aus den Wolkenschattenkarten wird die zu erwartende Sonnstrahlungsdichte geschätzt. Ohne jedoch die genaue (optische)</span></div><div><span>Beschaffenheit der Wolke und Atmosphäre (klarer Himmel) zu kennen ist diese stets fehlerbehaftet. Eine zusätzliche lokale</span></div><div><span>Messung zum Abgleichen der Vorhersage scheint unabdingbar zu sein (Messen mittels geeichter Photodiode)!</span></div><div><span>Ein verteiltes Netz von Messstationen könnte abhilfe leisten: (Macke and HOPE-Team, 2014] and (Madhavan, Kalisch, and Macke 2014;)</span></div><div><span>-Urquhart et al. (2013) analyze frequency distributions of PV power normalized to clear-sky conditions to determine a</span></div><div><span>clear and a cloudy mode and to assign them to shaded and unshaded cells, respectively.</span></div><div><span>-Gauchet et al. 2012 propose the use of a regression model in combination with a clear-sky model to estimate the</span></div><div><span>surface solar irradiance from segmented sky images with information about clear-sky, bright, and dark clouds; circumsolar</span></div><div><span>area; and solar disk.</span></div><div><span>############################################################################</span></div><div><span>#</span></div><div><span># Idee(n):</span></div><div><span>#</span></div><div><span>############################################################################</span></div><div><span>Lennfähiges (neurale Netze) mit cloud classification (optiche Dichte von Wolken)</span></div><div><span>Wolkenverteilung/-Form/ für patternrecognition? -&gt; kann daraus Zukünftiges abgeleitet werden?</span></div><div><span>Distanz Horizont zu Horizont:</span></div><div><span>-----------------------------</span></div><div><span>Distanz Horizont - Horizont ist abhängig von der Höhe (h) des Bebachters.</span></div><div><span>Horw Höhe über Meer: h = 441m</span></div><div><span>Wikipedia (unteschiedliche Modelle): <a href="https://en.wikipedia.org/wiki/Horizon">https://en.wikipedia.org/wiki/Horizon</a></span></div><div><span>ohne Effekte der Lichtbrechung: Apptoximation Beobachter-Horizont: d = 3.57*sqrt(h)</span></div><div><span>(where d is in kilometres and h is height above ground level in meter)</span></div><div><span>-&gt; Horw: d = 74.97 -&gt; Horizont - Horizont = 2*d = 149.94km</span></div><div><span>Möglicher forecast bei Windgesch 4m/s resp. 14.5km/h ca. 10h</span></div><div><span>Hingegen wenn h = 10m (Hausdach) -&gt; d = 3.57*sqrt(10) = 11.3km</span></div><div><span>Möglicher forecast bei 4m/s resp. 14.5km/h ca. = 0.78*60 = 45 Minuten</span></div><div><span>###########################################################################</span></div><div><span>#</span></div><div><span># Diverses:</span></div><div><span>#</span></div><div><span>############################################################################</span></div><div><span>Wolken Höhe und Geschwindigkeit aus den Flughafen-Meto Daten beziehen (METAR)</span></div><div><span><a href="https://www.euroairport.com/de/umwelt/flugbewegungen/erlaeuterung-metar.html">https://www.euroairport.com/de/umwelt/flugbewegungen/erlaeuterung-metar.html</a></span></div><div><span><a href="https://de.wikipedia.org/wiki/METAR">https://de.wikipedia.org/wiki/METAR</a></span></div><div><span>METAR DATEN als RAW-Daten beziehen: <a href="https://aviationweather.gov/metar/data?ids=LFSB&amp;format=raw&amp;date=0&amp;hours=0">https://aviationweather.gov/metar/data?ids=LFSB&amp;format=raw&amp;date=0&amp;hours=0</a></span></div><div><span>direkt aufgeschlüsselt: <a href="http://de.allmetsat.com/metar-taf/deutschland.php?icao=LSZH">http://de.allmetsat.com/metar-taf/deutschland.php?icao=LSZH</a></span></div><div><span>BSP Kloten ZH: METAR: LSZH 301220Z 24010KT 190V300 CAVOK 31/15 Q1013 NOSIG</span></div><div><span>###########################################################################</span></div><div><span>#</span></div><div><span># Kamera:</span></div><div><span>#</span></div><div><span>############################################################################</span></div><div><span>Auflösung pro Pixel: Chip rechteck mit x*y pixel. Bild wird auf diese Fläche projiziert.</span></div><div><span>fulcrum3d: Images are captured in full colour at a high sampling rate (~6s per image) to ensure small changes in cloud locations and shape are detected.</span></div><div><br/></div><div><br/></div><div><br/></div></en-note>]]></content><created>20170903T080654Z</created><updated>20170918T052634Z</updated><note-attributes><author>attila_horvath@gmx.ch</author><source>desktop.win</source><source-application>evernote.win32</source-application></note-attributes></note><note><title>To do Liste:</title><content><![CDATA[<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE en-note SYSTEM "http://xml.evernote.com/pub/enml2.dtd">

<en-note><div><b><u>To do Liste:</u></b></div><div>- find most recognized papers on subject.</div></en-note>]]></content><created>20170918T052456Z</created><updated>20170918T052530Z</updated><tag>To do</tag><note-attributes><author>attila_horvath@gmx.ch</author><source>desktop.win</source><source-application>evernote.win32</source-application></note-attributes></note></en-export>
